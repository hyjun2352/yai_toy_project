{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5e8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import MySQLdb\n",
    "import sklearn\n",
    "\n",
    "# import konlpy\n",
    "# from konlpy.tag import Twitter\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim import corpora, models\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim\n",
    "import pickle\n",
    "\n",
    "# from wordcloud import WordCloud\n",
    "# from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "from os import path\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, value\n",
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7abe1598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>가사</th>\n",
       "      <th>가수</th>\n",
       "      <th>발매일</th>\n",
       "      <th>좋아요수</th>\n",
       "      <th>장르</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이제 나만 믿어요</td>\n",
       "      <td>무얼 믿은 걸까 부족했던 내게서\\n나조차 못 믿던 내게 여태 머문 사람\\n무얼 봤던...</td>\n",
       "      <td>임영웅</td>\n",
       "      <td>2020.04.03</td>\n",
       "      <td>164,747</td>\n",
       "      <td>성인가요/트로트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>보금자리</td>\n",
       "      <td>그대 사랑이 나였음 좋겠다\\n아무것도 필요 없어요\\n든든한 품에 안겨 잠들고 싶어라...</td>\n",
       "      <td>임영웅</td>\n",
       "      <td>2022.05.02</td>\n",
       "      <td>43,816</td>\n",
       "      <td>성인가요/트로트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>찐이야</td>\n",
       "      <td>찐찐찐찐 찐이야 완전 찐이야\\n진짜가 나타났다 지금\\n찐찐찐찐 찐이야 완전 찐이야\\...</td>\n",
       "      <td>영탁</td>\n",
       "      <td>2020.03.13</td>\n",
       "      <td>66,514</td>\n",
       "      <td>성인가요/트로트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>니가 왜 거기서 나와 (Narr. 고은아)</td>\n",
       "      <td>어디야\\n집이야 피곤해서 일찍 자려구\\n아 그래 잠깐 볼랬더니\\n오늘 피곤했나 보네...</td>\n",
       "      <td>영탁</td>\n",
       "      <td>2018.10.21</td>\n",
       "      <td>61,103</td>\n",
       "      <td>성인가요/트로트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>별빛 같은 나의 사랑아</td>\n",
       "      <td>당신이 얼마나 내게\\n소중한 사람인지\\n세월이 흐르고 보니\\n이제 알 것 같아요\\n...</td>\n",
       "      <td>임영웅</td>\n",
       "      <td>2021.03.09</td>\n",
       "      <td>76,133</td>\n",
       "      <td>성인가요/트로트</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        제목                                                 가사  \\\n",
       "0                이제 나만 믿어요  무얼 믿은 걸까 부족했던 내게서\\n나조차 못 믿던 내게 여태 머문 사람\\n무얼 봤던...   \n",
       "1                     보금자리  그대 사랑이 나였음 좋겠다\\n아무것도 필요 없어요\\n든든한 품에 안겨 잠들고 싶어라...   \n",
       "2                      찐이야  찐찐찐찐 찐이야 완전 찐이야\\n진짜가 나타났다 지금\\n찐찐찐찐 찐이야 완전 찐이야\\...   \n",
       "3  니가 왜 거기서 나와 (Narr. 고은아)  어디야\\n집이야 피곤해서 일찍 자려구\\n아 그래 잠깐 볼랬더니\\n오늘 피곤했나 보네...   \n",
       "4             별빛 같은 나의 사랑아  당신이 얼마나 내게\\n소중한 사람인지\\n세월이 흐르고 보니\\n이제 알 것 같아요\\n...   \n",
       "\n",
       "    가수         발매일     좋아요수        장르  \n",
       "0  임영웅  2020.04.03  164,747  성인가요/트로트  \n",
       "1  임영웅  2022.05.02   43,816  성인가요/트로트  \n",
       "2   영탁  2020.03.13   66,514  성인가요/트로트  \n",
       "3   영탁  2018.10.21   61,103  성인가요/트로트  \n",
       "4  임영웅  2021.03.09   76,133  성인가요/트로트  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiphop = pd.read_csv('melon_trot_1_3500.csv')\n",
    "hiphop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75477f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['제목', '가사', '가수', '발매일', '좋아요수', '장르'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiphop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9f3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PREMADE_TEXT = False\n",
    "\n",
    "text_filepath = 'word2vec/all_lyrics_text.txt'\n",
    "if not USE_PREMADE_TEXT:\n",
    "    with open(text_filepath, 'w', encoding='utf-8') as f:\n",
    "        for lyrics in hiphop['가사'].values:\n",
    "            if pd.isnull(lyrics): # null값 있다면 그 다음으로 넘어감\n",
    "                continue\n",
    "            f.write(lyrics + '\\n')\n",
    "else:\n",
    "    assert path.exists(text_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2359ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PREMADE_BIGRAM_MODEL = False\n",
    "\n",
    "all_bigram_model_filepath = 'word2vec/all_bigram_model'\n",
    "all_sentences_normalized_filepath = 'word2vec/all_lyrics_text.txt'\n",
    "\n",
    "all_unigram_sentences = LineSentence(all_sentences_normalized_filepath)\n",
    "\n",
    "if not USE_PREMADE_BIGRAM_MODEL:    \n",
    "    \n",
    "    all_bigram_model = Phrases(all_unigram_sentences) #phrase냐 아니냐를 판단해줌\n",
    "    all_bigram_model.save(all_bigram_model_filepath)\n",
    "    \n",
    "else:\n",
    "    all_bigram_model = Phrases.load(all_bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5630ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PREMADE_BIGRAM_SENTENCES = False\n",
    "\n",
    "all_bigram_sentences_filepath = 'word2vec/all_sentences_for_word2vec.txt'\n",
    "\n",
    "if not USE_PREMADE_BIGRAM_SENTENCES:\n",
    "    \n",
    "    with open(all_bigram_sentences_filepath, 'w', encoding='utf-8') as f:\n",
    "        for unigram_sentence in all_unigram_sentences:\n",
    "            all_bigram_sentence = all_bigram_model[unigram_sentence]\n",
    "            f.write(' '.join(all_bigram_sentence) + '\\n')\n",
    "else:\n",
    "    assert path.exists(all_bigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45937851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khyj0\\AppData\\Local\\Temp\\ipykernel_10884\\1412957348.py:21: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  all2vec.init_sims()\n"
     ]
    }
   ],
   "source": [
    "USE_PREMADE_WORD2VEC = False\n",
    "\n",
    "all2vec_filepath = 'word2vec/all_word2vec_model'\n",
    "\n",
    "if not USE_PREMADE_WORD2VEC:\n",
    "    \n",
    "    lyrics_for_word2vec = LineSentence(all_bigram_sentences_filepath)\n",
    "\n",
    "    all2vec = Word2Vec(lyrics_for_word2vec, vector_size=100, window=5, min_count=1, sg=1)\n",
    "    # sg=0 cbow 1=Skip-Gram Model\n",
    "    # 100차원으로 가져옴 / 보통 20~100 정도\n",
    "    # window = 5 앞 5개, 뒤 5개 단어를 보겠다는 뜻\n",
    "    # window size 작을수록 문법적인 의미가 너무 중요해짐, 클수록 주제 지향적으로 문맥적인 정보를 많이 담게 됨    \n",
    "    for _ in range(9):\n",
    "        all2vec.train(lyrics_for_word2vec, total_examples=81085, epochs=1)\n",
    "        # 9139곡 가사에 총 789847 문장이 있다는 것 명시\n",
    "        \n",
    "    all2vec.save(all2vec_filepath)\n",
    "else:\n",
    "    all2vec = Word2Vec.load(all2vec_filepath)\n",
    "all2vec.init_sims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba2c9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all2vec_filepath = 'word2vec/all_word2vec_model'\n",
    "all2vec = Word2Vec.load(all2vec_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c43958f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('얘기_들려줬지', 0.8530884981155396),\n",
       " ('어릿광대의_서글픈', 0.8415049910545349),\n",
       " ('허락한', 0.8361315727233887),\n",
       " ('지워지지않는', 0.8341256380081177),\n",
       " ('바라보는것도', 0.833894670009613)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all2vec.wv.most_similar(positive=['사랑'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d648f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('눈매에', 0.899547278881073),\n",
       " ('나는야_당신의', 0.8945144414901733),\n",
       " ('눈물인가', 0.8890373110771179),\n",
       " ('다칠까', 0.8875921964645386),\n",
       " ('친정엄마', 0.8873438835144043)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all2vec.wv.most_similar(positive=['엄마'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2780a58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>내</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사랑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   내\n",
       "1   그\n",
       "2  사랑\n",
       "3  내가\n",
       "4  나는"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(all2vec.wv.index_to_key)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c61b7464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32851"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b370fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3650"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "cnt = all2vec.wv.index_to_key[0]\n",
    "all2vec.wv.get_vecattr(cnt, \"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a32ab550",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(all2vec\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mkey_to_index)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "a, b = enumerate(all2vec.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "205e8ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = []\n",
    "for i in (range(32851)):\n",
    "    cnt_num = all2vec.wv.index_to_key[i]\n",
    "    cnt = all2vec.wv.get_vecattr(cnt_num, \"count\")\n",
    "    if cnt > 50:\n",
    "        words.append(a[0][i]) # 횟수 100회 초과하는 단어만 리스트화\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c65c5e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb2bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in words:\n",
    "    X.append(all2vec.wv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dedf630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acb5555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.DataFrame(X, index = words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "feec5553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>내</th>\n",
       "      <td>-0.127160</td>\n",
       "      <td>0.347227</td>\n",
       "      <td>1.025615</td>\n",
       "      <td>1.389813</td>\n",
       "      <td>-0.513000</td>\n",
       "      <td>-0.288353</td>\n",
       "      <td>0.889202</td>\n",
       "      <td>1.380382</td>\n",
       "      <td>-1.316874</td>\n",
       "      <td>-0.478238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.465904</td>\n",
       "      <td>-0.466688</td>\n",
       "      <td>-0.015125</td>\n",
       "      <td>-0.004280</td>\n",
       "      <td>1.069456</td>\n",
       "      <td>0.187512</td>\n",
       "      <td>-1.144948</td>\n",
       "      <td>-1.364540</td>\n",
       "      <td>-0.579646</td>\n",
       "      <td>0.988877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>그</th>\n",
       "      <td>0.175666</td>\n",
       "      <td>0.531102</td>\n",
       "      <td>0.838579</td>\n",
       "      <td>0.828473</td>\n",
       "      <td>0.626963</td>\n",
       "      <td>-0.816397</td>\n",
       "      <td>0.641528</td>\n",
       "      <td>1.423779</td>\n",
       "      <td>-1.280882</td>\n",
       "      <td>-0.290818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325337</td>\n",
       "      <td>-0.161043</td>\n",
       "      <td>0.152332</td>\n",
       "      <td>-0.295510</td>\n",
       "      <td>0.330040</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.488532</td>\n",
       "      <td>-0.657473</td>\n",
       "      <td>-0.739030</td>\n",
       "      <td>0.051141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사랑</th>\n",
       "      <td>-0.329151</td>\n",
       "      <td>0.504518</td>\n",
       "      <td>-0.183613</td>\n",
       "      <td>-0.830748</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.172776</td>\n",
       "      <td>-0.183977</td>\n",
       "      <td>1.904319</td>\n",
       "      <td>-0.301512</td>\n",
       "      <td>0.732476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098623</td>\n",
       "      <td>0.150958</td>\n",
       "      <td>0.296161</td>\n",
       "      <td>-0.049999</td>\n",
       "      <td>0.369038</td>\n",
       "      <td>0.351164</td>\n",
       "      <td>0.037221</td>\n",
       "      <td>-0.870418</td>\n",
       "      <td>0.638110</td>\n",
       "      <td>0.064619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>내가</th>\n",
       "      <td>-1.360136</td>\n",
       "      <td>1.170185</td>\n",
       "      <td>-0.180422</td>\n",
       "      <td>0.135618</td>\n",
       "      <td>0.808104</td>\n",
       "      <td>-0.691902</td>\n",
       "      <td>0.319708</td>\n",
       "      <td>1.748021</td>\n",
       "      <td>-0.053824</td>\n",
       "      <td>-0.960122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038012</td>\n",
       "      <td>-0.095856</td>\n",
       "      <td>0.061209</td>\n",
       "      <td>-0.329640</td>\n",
       "      <td>1.131410</td>\n",
       "      <td>-0.683070</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>-0.463874</td>\n",
       "      <td>-0.584364</td>\n",
       "      <td>-0.134720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>나는</th>\n",
       "      <td>-0.310809</td>\n",
       "      <td>-0.308096</td>\n",
       "      <td>-1.005908</td>\n",
       "      <td>0.660476</td>\n",
       "      <td>0.272325</td>\n",
       "      <td>-0.341635</td>\n",
       "      <td>0.364656</td>\n",
       "      <td>2.086610</td>\n",
       "      <td>-0.543671</td>\n",
       "      <td>0.221481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>-0.392389</td>\n",
       "      <td>1.528759</td>\n",
       "      <td>0.596684</td>\n",
       "      <td>0.971814</td>\n",
       "      <td>-0.848647</td>\n",
       "      <td>0.491822</td>\n",
       "      <td>0.655076</td>\n",
       "      <td>0.276638</td>\n",
       "      <td>0.606988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "내  -0.127160  0.347227  1.025615  1.389813 -0.513000 -0.288353  0.889202   \n",
       "그   0.175666  0.531102  0.838579  0.828473  0.626963 -0.816397  0.641528   \n",
       "사랑 -0.329151  0.504518 -0.183613 -0.830748  0.008155  0.172776 -0.183977   \n",
       "내가 -1.360136  1.170185 -0.180422  0.135618  0.808104 -0.691902  0.319708   \n",
       "나는 -0.310809 -0.308096 -1.005908  0.660476  0.272325 -0.341635  0.364656   \n",
       "\n",
       "          7         8         9   ...        90        91        92        93  \\\n",
       "내   1.380382 -1.316874 -0.478238  ... -0.465904 -0.466688 -0.015125 -0.004280   \n",
       "그   1.423779 -1.280882 -0.290818  ...  0.325337 -0.161043  0.152332 -0.295510   \n",
       "사랑  1.904319 -0.301512  0.732476  ...  0.098623  0.150958  0.296161 -0.049999   \n",
       "내가  1.748021 -0.053824 -0.960122  ... -0.038012 -0.095856  0.061209 -0.329640   \n",
       "나는  2.086610 -0.543671  0.221481  ...  0.813084 -0.392389  1.528759  0.596684   \n",
       "\n",
       "          94        95        96        97        98        99  \n",
       "내   1.069456  0.187512 -1.144948 -1.364540 -0.579646  0.988877  \n",
       "그   0.330040  0.011329  0.488532 -0.657473 -0.739030  0.051141  \n",
       "사랑  0.369038  0.351164  0.037221 -0.870418  0.638110  0.064619  \n",
       "내가  1.131410 -0.683070  0.518767 -0.463874 -0.584364 -0.134720  \n",
       "나는  0.971814 -0.848647  0.491822  0.655076  0.276638  0.606988  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "275b0add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khyj0\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\khyj0\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "USE_PREMADE_TSNE = False\n",
    "\n",
    "tsne_filepath = 'word2vec/tsne.pkl'\n",
    "\n",
    "if not USE_PREMADE_TSNE:\n",
    "    \n",
    "    tsne = TSNE(random_state=0)\n",
    "    tsne_points = tsne.fit_transform(X2)\n",
    "    with open(tsne_filepath, 'wb') as f:\n",
    "        pickle.dump(tsne_points, f)\n",
    "else:\n",
    "    with open(tsne_filepath, 'rb') as f:\n",
    "        tsne_points = pickle.load(f)\n",
    "\n",
    "tsne_df = pd.DataFrame(tsne_points, index=X2.index, columns=['x_coord', 'y_coord'])\n",
    "tsne_df['word'] = tsne_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "437c9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data in a form suitable for bokeh.\n",
    "plot_data = ColumnDataSource(tsne_df)\n",
    "\n",
    "# create the plot and configure it\n",
    "tsne_plot = figure(title=\"t-SNE Word Embeddings\",\n",
    "                   plot_width = 800,\n",
    "                   plot_height = 800,\n",
    "                   active_scroll='wheel_zoom'\n",
    "                  )\n",
    "\n",
    "# add a hover tool to display words on roll-over\n",
    "tsne_plot.add_tools( HoverTool(tooltips = '@word') )\n",
    "\n",
    "tsne_plot.circle('x_coord', 'y_coord', source=plot_data,\n",
    "                 color='red', line_alpha=0.2, fill_alpha=0.1,\n",
    "                 size=10, hover_line_color='orange')\n",
    "\n",
    "# adjust visual elements of the plot\n",
    "tsne_plot.xaxis.visible = False\n",
    "tsne_plot.yaxis.visible = False\n",
    "tsne_plot.grid.grid_line_color = None\n",
    "tsne_plot.outline_line_color = None\n",
    "\n",
    "# show time!\n",
    "show(tsne_plot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e19e22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "data = list()\n",
    "f = open(\"word2vec/all_lyrics_text.txt\",'r',encoding='utf-8-sig')\n",
    "rea = csv.reader(f)\n",
    "for row in rea:\n",
    "    data.append(row)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6c021a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c42a5c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'무'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(lyrics)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m [char2idx[char] \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m lyrics]\n\u001b[0;32m      5\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(lyrics, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m      6\u001b[0m lyrics\u001b[38;5;241m.\u001b[39mtensor\n",
      "Cell \u001b[1;32mIn[77], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(lyrics)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m [\u001b[43mchar2idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m lyrics]\n\u001b[0;32m      5\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(lyrics, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m      6\u001b[0m lyrics\u001b[38;5;241m.\u001b[39mtensor\n",
      "\u001b[1;31mKeyError\u001b[0m: '무'"
     ]
    }
   ],
   "source": [
    "f = open('word2vec/all_lyrics_text.txt', 'r' , encoding = 'utf8')\n",
    "lyrics = f.read()\n",
    "# print(lyrics)\n",
    "lyrics = [char2idx[char] for char in lyrics]\n",
    "lyrics = torch.tensor(lyrics, dtype=torch.long)\n",
    "lyrics.tensor\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7df7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics = \"\"\"\n",
    "# 날 적시는 기억 속에 난\n",
    "# 꼭 필요한 한 조각\n",
    "# 다 떠나버린 너의 기억도\n",
    "# 한 조각 씩 널 잊어가\n",
    "# \"\"\"\n",
    "\n",
    "# 데이터 전처리\n",
    "chars = list(set(lyrics))\n",
    "char2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2char = {i: c for i, c in enumerate(chars)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a80c2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LyricsGenerator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        lstm_out, hidden = self.lstm(inputs, hidden)\n",
    "        output = self.linear(lstm_out.view(len(inputs), -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))\n",
    "\n",
    "input_size = len(chars)\n",
    "hidden_size = 128\n",
    "output_size = len(chars)\n",
    "model = LyricsGenerator(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eabbda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, lyrics, n_epochs=1000, print_every=100):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # 데이터 전처리\n",
    "        input_seq = [char2idx[c] for c in lyrics[:-1]]\n",
    "        target_seq = [char2idx[c] for c in lyrics[1:]]\n",
    "        input_tensor = torch.tensor(input_seq, dtype=torch.long).unsqueeze(1)\n",
    "        target_tensor = torch.tensor(target_seq, dtype=torch.long).unsqueeze(1)\n",
    "\n",
    "        # 초기화\n",
    "        hidden = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델 예측\n",
    "        loss = 0\n",
    "        for i in range(len(input_seq)):\n",
    "            output, hidden = model(input_tensor[i], hidden)\n",
    "            loss += loss_fn(output, target_tensor[i])\n",
    "\n",
    "        # 역전파 및 가중치 갱신\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 결과 출력\n",
    "        if epoch % print_every == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch, n_epochs, loss.item() / len(input_seq)))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1a8b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eaea4581",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "tensor(1169)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 학습 수행\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlyrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[70], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_fn, lyrics, n_epochs, print_every)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, optimizer, loss_fn, lyrics, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# 데이터 전처리\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m         input_seq \u001b[38;5;241m=\u001b[39m [char2idx[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m lyrics[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m      5\u001b[0m         target_seq \u001b[38;5;241m=\u001b[39m [char2idx[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m lyrics[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m      6\u001b[0m         input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input_seq, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[70], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, optimizer, loss_fn, lyrics, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# 데이터 전처리\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m         input_seq \u001b[38;5;241m=\u001b[39m [\u001b[43mchar2idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m lyrics[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m      5\u001b[0m         target_seq \u001b[38;5;241m=\u001b[39m [char2idx[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m lyrics[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m      6\u001b[0m         input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input_seq, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: tensor(1169)"
     ]
    }
   ],
   "source": [
    "# 손실 함수 설정\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습 수행\n",
    "model = train(model, optimizer, loss_fn, lyrics, n_epochs=10000, print_every=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95133367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(model, start_char, length):\n",
    "    # 시작 문자 입력\n",
    "    input_char = start_char\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    # 생성된 가사\n",
    "    generated_lyrics = start_char\n",
    "\n",
    "    # 모델 예측 및 다음 문자 예측\n",
    "    for i in range(length):\n",
    "        input_tensor = torch.tensor([char2idx[input_char]], dtype=torch.long).unsqueeze(1)\n",
    "        output, hidden = model(input_tensor, hidden)\n",
    "        output_dist = output.data.view(-1).exp()\n",
    "        top_char_idx = torch.multinomial(output_dist, 1)[0]\n",
    "        input_char = idx2char[top_char_idx.item()]\n",
    "        generated_lyrics += input_char\n",
    "\n",
    "    return generated_lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4bd919",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_lyrics = generate_lyrics(model, '난', 200)\n",
    "print(generated_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "380714e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 17\u001b[0m\n\u001b[0;32m      7\u001b[0m alphabet \u001b[38;5;241m=\u001b[39m string\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 가사 데이터\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# data = [\"hello world\",\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#         \"the quick brown fox jumps over the lazy dog\",\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 문자를 숫자로 변환하는 딕셔너리 생성\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m char_to_index \u001b[38;5;241m=\u001b[39m {char: index \u001b[38;5;28;01mfor\u001b[39;00m (index, char) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 숫자를 문자로 변환하는 딕셔너리 생성\u001b[39;00m\n\u001b[0;32m     20\u001b[0m index_to_char \u001b[38;5;241m=\u001b[39m {index: char \u001b[38;5;28;01mfor\u001b[39;00m (index, char) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(alphabet)}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not iterable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import random\n",
    "\n",
    "# 가사 생성에 사용할 알파벳\n",
    "alphabet = string.ascii_lowercase + \" \"\n",
    "\n",
    "# 가사 데이터\n",
    "# data = [\"hello world\",\n",
    "#         \"the quick brown fox jumps over the lazy dog\",\n",
    "#         \"you only live once\",\n",
    "#         \"don't stop believing\",\n",
    "#         \"i love you\"]\n",
    "\n",
    "# 문자를 숫자로 변환하는 딕셔너리 생성\n",
    "char_to_index = {char: index for (index, char) in enumerate(alphabet)}\n",
    "\n",
    "# 숫자를 문자로 변환하는 딕셔너리 생성\n",
    "index_to_char = {index: char for (index, char) in enumerate(alphabet)}\n",
    "\n",
    "# 시퀀스의 최대 길이\n",
    "max_sequence_length = max([len(seq) for seq in data])\n",
    "\n",
    "# 입력 시퀀스와 출력 시퀀스 생성\n",
    "input_sequences = []\n",
    "output_sequences = []\n",
    "for seq in data:\n",
    "    # 입력 시퀀스\n",
    "    input_seq = seq\n",
    "    # 출력 시퀀스\n",
    "    output_seq = seq\n",
    "    # 시퀀스를 숫자로 변환\n",
    "    input_seq = [char_to_index[char] for char in input_seq]\n",
    "    output_seq = [char_to_index[char] for char in output_seq]\n",
    "    # 시퀀스 길이가 최대 길이보다 작으면 패딩 추가\n",
    "    input_seq += [char_to_index[\" \"]] * (max_sequence_length - len(input_seq))\n",
    "    output_seq += [char_to_index[\" \"]] * (max_sequence_length - len(output_seq))\n",
    "    # 입력 시퀀스와 출력 시퀀스 저장\n",
    "    input_sequences.append(input_seq)\n",
    "    output_sequences.append(output_seq)\n",
    "\n",
    "# 텐서로 변환\n",
    "input_sequences = torch.tensor(input_sequences)\n",
    "output_sequences = torch.tensor(output_sequences)\n",
    "\n",
    "# RNN-LSTM 모델 정의\n",
    "class RNNLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNNLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "        out, _ = self.lstm2(out, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 모델 초기화\n",
    "input_size = len(alphabet)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = len(alphabet)\n",
    "model = RNNLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# 손실 함수와 최적화 알고리즘 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_sequences)\n",
    "    loss = criterion(outputs.view(-1, output_size), output_sequences.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# 가사 생성\n",
    "generated_text = \"\"\n",
    "start_sequence = \"나는\"\n",
    "with torch.no_grad():\n",
    "    # 시작 시퀀스를 입력으로 사용\n",
    "    input_seq = start_sequence.lower()\n",
    "    input_seq = [char_to_index[char] for char in input_seq]\n",
    "    input_seq = torch.tensor(input_seq).unsqueeze(0)\n",
    "    # 모델이 다음 문자를 예측하도록 설정\n",
    "    model.eval()\n",
    "    for i in range(max_sequence_length):\n",
    "        output = model(input_seq)\n",
    "        # 확률이 가장 높은 문자를 선택하여 출력 문자열에 추가\n",
    "        _, predicted = torch.max(output, 2)\n",
    "        char = index_to_char[predicted.item()]\n",
    "        generated_text += char\n",
    "        # 이전 출력을 다음 입력으로 사용\n",
    "        input_seq = predicted.unsqueeze(0)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c5009ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import torch\n",
    "\n",
    "class TextLoader:\n",
    "    def __init__(self, path):\n",
    "        with open(path, \"r\", encoding='utf-8') as _file:\n",
    "            self.text = _file.read().split()\n",
    "\n",
    "        self.song2vec = Word2Vec.load(\"word2vec/all_word2vec_model\")\n",
    "        self.vocab, self.words = self.build_vocab()\n",
    "\n",
    "        self.X = self.text[:]\n",
    "        self.y = [self.text[0]] + self.text[1:]\n",
    "\n",
    "    def build_vocab(self):\n",
    "        vocab_inv = list(self.song2vec.wv.index_to_key)\n",
    "        vocab = {x: i for i, x in enumerate(vocab_inv)}\n",
    "        return vocab, vocab_inv\n",
    "\n",
    "    def next_batch(self, batch_size, seq_length):\n",
    "        start = np.random.randint(0, len(self.X)-batch_size*seq_length)\n",
    "        end   = start + batch_size*seq_length\n",
    "\n",
    "        X_words = self.X[start:end]\n",
    "        y_words = self.y[start:end]\n",
    "\n",
    "        X_idx = torch.empty((batch_size, seq_length), dtype=torch.int64)\n",
    "        y_idx = torch.empty((batch_size, seq_length), dtype=torch.int64)\n",
    "        X_wv = torch.empty((batch_size, seq_length, 100))\n",
    "        y_wv = torch.empty((batch_size, seq_length, 100))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_length):\n",
    "                X_idx[i, j] = self.vocab[X_words[i*seq_length+j]]\n",
    "                y_idx[i, j] = self.vocab[y_words[i*seq_length+j]]\n",
    "\n",
    "                X_wv[i, j] = torch.tensor(self.song2vec.wv[X_words[i*seq_length+j]])\n",
    "                y_wv[i, j] = torch.tensor(self.song2vec.wv[y_words[i*seq_length+j]])\n",
    "\n",
    "        return X_wv, X_idx, y_wv, y_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f531058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building graph of deps:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Examining @/win-64::__archspec==1=x86_64:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Examining @/win-64::__win==0=0:  25%|##5       | 1/4 [00:00<00:00, 1446.81it/s]\n",
      "Examining tensorflow==1.15:  50%|#####     | 2/4 [00:00<00:00, 2893.62it/s]    \n",
      "Examining python=3.9:  75%|#######5  | 3/4 [00:00<00:00, 52.92it/s]        \n",
      "                                                                   \n",
      "\n",
      "Determining conflicts:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Examining conflict for tensorflow python:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "                                                                               \n",
      "\n",
      "UnsatisfiableError: The following specifications were found\n",
      "to be incompatible with the existing python installation in your environment:\n",
      "\n",
      "Specifications:\n",
      "\n",
      "  - tensorflow==1.15 -> python[version='3.6.*|3.7.*']\n",
      "\n",
      "Your python: python=3.9\n",
      "\n",
      "If python is on the left-most side of the chain, that's the version you've asked for.\n",
      "When python appears to the right, that indicates that the thing on the left is somehow\n",
      "not available for the python version you are constrained to. Note that conda will not\n",
      "change your python version to a different minor version unless you explicitly specify\n",
      "that.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "127e459b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrnn\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlayers\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.layers as layers\n",
    "import tensorflow.contrib.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc8466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers  = 3\n",
    "hidden_size = 512\n",
    "batch_size  = 1 # 1글자\n",
    "# max_length  = 1 # 1로 하는것으로~\n",
    "\n",
    "loader = TextLoader(\"word2vec/all_sentences_for_word2vec.txt\")\n",
    "vocab_size = len(loader.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc9e44b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_softmax \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(y_softmax, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(pred, [batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:956\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "y_softmax = tf.nn.softmax(logits)\n",
    "pred = tf.argmax(y_softmax, axis=1)\n",
    "pred = tf.reshape(pred, [batch_size, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d63b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, None, 100])\n",
    "# x_one_hot = tf.one_hot(X, vocab_size)\n",
    "\n",
    "cells = [rnn.BasicLSTMCell(hidden_size) for _ in range(num_layers)]\n",
    "cells = rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "initial_state = cells.zero_state(batch_size, tf.float32)\n",
    "outputs, states = tf.nn.dynamic_rnn(cells, X,\n",
    "                                    initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "\n",
    "outputs = tf.reshape(outputs, [-1, hidden_size])\n",
    "logits = layers.linear(outputs, vocab_size) # linear\n",
    "#                                 ,activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c10ef095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕', '나는', '너야']\n",
      "Start with: 안녕 나는 너야\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'Saver'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentence)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart with:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sentence))\n\u001b[1;32m----> 6\u001b[0m saver \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSaver\u001b[49m()\n\u001b[0;32m      7\u001b[0m sess_config \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mConfigProto(gpu_options\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mGPUOptions(allow_growth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mSession(config\u001b[38;5;241m=\u001b[39msess_config) \u001b[38;5;28;01mas\u001b[39;00m sess:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'Saver'"
     ]
    }
   ],
   "source": [
    "# 시작 글자 생성\n",
    "sentence = [\"안녕\", \"나는\", \"너야\"]\n",
    "print(sentence)\n",
    "print(\"Start with:\", \" \".join(sentence))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"char-rnn_230000\")\n",
    "    \n",
    "    # [배치사이즈, max_length, 100]\n",
    "    vec = np.empty((1, len(sentence), 100)) # 시작 글자를 주고 다음 단어를 예측 - 시작으로 준 것을 전부 다 입력으로 넣겠다\n",
    "    for i, word in enumerate(sentence):\n",
    "        vec[:, i, :] = loader.song2vec.wv[word]\n",
    "    \n",
    "    # 매 이터레이션마다 글자 하나씩 생성\n",
    "    state = sess.run(states, feed_dict={X: vec}) #입력단어 sentence 이후에 들어올 단어를 예측\n",
    "    for i in range(15): # for문을 돌면서 풀어헤치는 중!!\n",
    "        vec = loader.song2vec.wv[sentence[-1]].reshape(1, 1, 100)\n",
    "        \n",
    "        pred_char, state = sess.run([pred, states], \n",
    "            feed_dict={X: vec, initial_state: state}) # 원래 initial stete 는 0 이었으나\n",
    "        # 이전 스텝에 갖고 있는 state 값을 다음 스텝에 넣어줌 // 입력단어들을 그 다음 스텝에 넣어주는 것임\n",
    "        \n",
    "        pred_char = loader.words[pred_char[0][-1]]\n",
    "        sentence.append(pred_char)\n",
    "\n",
    "for i, word in enumerate(sentence):\n",
    "    print(word, end=\" \")\n",
    "    if (i+1) % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b88393b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'word2vec/all_word2vec.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     42\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 44\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mTextLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword2vec/all_sentences_for_word2vec.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader\u001b[38;5;241m.\u001b[39mvocab)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Create the model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[29], line 19\u001b[0m, in \u001b[0;36mTextLoader.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx2char \u001b[38;5;241m=\u001b[39m {i: c \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab)}\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar2idx[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msong2vec \u001b[38;5;241m=\u001b[39m \u001b[43mWord2Vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword2vec/all_word2vec.model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py:1930\u001b[0m, in \u001b[0;36mWord2Vec.load\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m \n\u001b[0;32m   1913\u001b[0m \u001b[38;5;124;03mSee Also\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \n\u001b[0;32m   1928\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1929\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1930\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(Word2Vec, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Word2Vec):\n\u001b[0;32m   1932\u001b[0m         rethrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\utils.py:485\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    481\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m object from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, fname)\n\u001b[0;32m    483\u001b[0m compress, subname \u001b[38;5;241m=\u001b[39m SaveLoad\u001b[38;5;241m.\u001b[39m_adapt_by_suffix(fname)\n\u001b[1;32m--> 485\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m obj\u001b[38;5;241m.\u001b[39m_load_specials(fname, mmap, compress, subname)\n\u001b[0;32m    487\u001b[0m obj\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded\u001b[39m\u001b[38;5;124m\"\u001b[39m, fname\u001b[38;5;241m=\u001b[39mfname)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1459\u001b[0m, in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munpickle\u001b[39m(fname):\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[0;32m   1448\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1457\u001b[0m \n\u001b[0;32m   1458\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1459\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m   1460\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _pickle\u001b[38;5;241m.\u001b[39mload(f, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:188\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     transport_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 188\u001b[0m fobj \u001b[38;5;241m=\u001b[39m \u001b[43m_shortcut_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:361\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    359\u001b[0m     open_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m errors\n\u001b[1;32m--> 361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[38;5;241m=\u001b[39mbuffering, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'word2vec/all_word2vec.model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import codecs\n",
    "\n",
    "class TextLoader:\n",
    "    def __init__(self, filename):\n",
    "        with codecs.open(filename, 'r', encoding='utf-8') as f:\n",
    "            self.text = f.read()\n",
    "            self.vocab = sorted(list(set(self.text)))\n",
    "\n",
    "        self.char2idx = {c: i for i, c in enumerate(self.vocab)}\n",
    "        self.idx2char = {i: c for i, c in enumerate(self.vocab)}\n",
    "\n",
    "        self.encoded = np.array([self.char2idx[c] for c in self.text], dtype=np.int32)\n",
    "\n",
    "        self.song2vec = Word2Vec.load(\"word2vec/all_word2vec.model\")\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "# Hyperparameters\n",
    "num_layers = 3\n",
    "hidden_size = 512\n",
    "batch_size = 1\n",
    "seq_length = 1\n",
    "\n",
    "loader = TextLoader(\"word2vec/all_sentences_for_word2vec.txt\")\n",
    "vocab_size = len(loader.vocab)\n",
    "\n",
    "# Create the model\n",
    "model = CharRNN(vocab_size, hidden_size, vocab_size, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Load the saved model\n",
    "model.load_state_dict(torch.load('char-rnn_230000'))\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Starting words\n",
    "sentence = [\"안녕\", \"나는\", \"너야\"]\n",
    "print(sentence)\n",
    "print(\"Start with:\", \" \".join(sentence))\n",
    "\n",
    "# Convert starting words to vectors\n",
    "vec = torch.empty((1, len(sentence), 100))\n",
    "for i, word in enumerate(sentence):\n",
    "    vec[0, i, :] = torch.from_numpy(loader.song2vec.wv[word])\n",
    "\n",
    "# Set initial hidden state\n",
    "hidden = None\n",
    "\n",
    "# Generate characters one at a time\n",
    "for i in range(15):\n",
    "    # Get the vector for the last generated word\n",
    "    vec = torch.from_numpy(loader.song2vec.wv[sentence[-1]]).reshape(1, 1, 100)\n",
    "\n",
    "    # Feed the vector and hidden state to the model to get the next predicted word\n",
    "    output, hidden = model(vec, hidden)\n",
    "    _, pred = torch.max(output, dim=1)\n",
    "\n",
    "    # Convert the predicted word index to a character\n",
    "    pred_char = loader.idx2char[pred.item()]\n",
    "    sentence.append(pred_char)\n",
    "\n",
    "# Print the generated sentence\n",
    "for i, word in enumerate(sentence):\n",
    "    print(word, end=\" \")\n",
    "    if (i+1) % 5 == 0:\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7ab8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
